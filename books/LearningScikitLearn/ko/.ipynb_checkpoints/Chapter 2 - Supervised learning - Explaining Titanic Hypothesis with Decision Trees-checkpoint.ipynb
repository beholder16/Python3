{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn 배우기: 파이썬과 기계 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2장 : 지도 학습 - 결정 트리로 타이타닉 가설 설명하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전처리하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저, 데이터셋을 로드한다. data/titanic.csv파일을 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "with open('data/titanic.csv', 'rb') as csvfile:\n",
    "    titanic_reader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "    \n",
    "    # 헤더에 속성 이름이 있다\n",
    "    row = titanic_reader.next()\n",
    "    feature_names = np.array(row)\n",
    "    \n",
    "    # 데이터셋와 목적 범주를 로드한다\n",
    "    titanic_X, titanic_y = [], []\n",
    "    for row in titanic_reader:  \n",
    "        titanic_X.append(row)\n",
    "        titanic_y.append(row[2]) # 목적값은 \"생존\"이다\n",
    "    \n",
    "    titanic_X = np.array(titanic_X)\n",
    "    titanic_y = np.array(titanic_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['row.names' 'pclass' 'survived' 'name' 'age' 'embarked' 'home.dest' 'room'\n",
      " 'ticket' 'boat' 'sex'] ['1' '1st' '1' 'Allen, Miss Elisabeth Walton' '29.0000' 'Southampton'\n",
      " 'St Louis, MO' 'B-5' '24160 L221' '2' 'female'] 1\n"
     ]
    }
   ],
   "source": [
    "print feature_names, titanic_X[0], titanic_y[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "선실 등급, 나이, 성별을 사용한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 선실 등급, 나이, 성별을 사용한다\n",
    "titanic_X = titanic_X[:, [1, 4, 10]]\n",
    "feature_names = feature_names[[1, 4, 10]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pclass' 'age' 'sex']\n",
      "['1st' 'NA' 'female'] 1\n"
     ]
    }
   ],
   "source": [
    "print feature_names\n",
    "print titanic_X[12], titanic_y[12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "나이에 대한 결측치('NA')에 평균 나이를 넣는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 결측치가 있다. 평균 나이로 한다\n",
    "ages = titanic_X[:, 1]\n",
    "mean_age = np.mean(titanic_X[ages != 'NA', 1].astype(np.float))\n",
    "titanic_X[titanic_X[:, 1] == 'NA', 1] = mean_age\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pclass' 'age' 'sex']\n",
      "['1st' '31.1941810427' 'female'] 1\n"
     ]
    }
   ],
   "source": [
    "print feature_names\n",
    "print titanic_X[12], titanic_y[12]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "선실 등급, 성별은 범주적 속성이다. 성별은 이진값으로 변환할 수 있다(0=여성,1=남성):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical classes: ['female' 'male']\n",
      "Integer classes: [0 1]\n"
     ]
    }
   ],
   "source": [
    "# 성별 인코딩\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "enc = LabelEncoder()\n",
    "label_encoder = enc.fit(titanic_X[:, 2])\n",
    "print \"Categorical classes:\", label_encoder.classes_\n",
    "integer_classes = label_encoder.transform(label_encoder.classes_)\n",
    "print \"Integer classes:\", integer_classes\n",
    "t = label_encoder.transform(titanic_X[:, 2])\n",
    "titanic_X[:, 2] = t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pclass' 'age' 'sex']\n",
      "['1st' '31.1941810427' '0'] 1\n"
     ]
    }
   ],
   "source": [
    "print feature_names\n",
    "print titanic_X[12], titanic_y[12]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OneHotEncoder을 사용하여 범주를 변환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical classes: ['1st' '2nd' '3rd']\n",
      "Integer classes: [[0]\n",
      " [1]\n",
      " [2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = LabelEncoder()\n",
    "label_encoder = enc.fit(titanic_X[:, 0])\n",
    "print \"Categorical classes:\", label_encoder.classes_\n",
    "integer_classes = label_encoder.transform(label_encoder.classes_).reshape(3, 1)\n",
    "print \"Integer classes:\", integer_classes\n",
    "enc = OneHotEncoder()\n",
    "one_hot_encoder = enc.fit(integer_classes)\n",
    "# 먼저, label_encoder을 사용하여 범주를 0-(N-1)정수로 변환한다\n",
    "num_of_rows = titanic_X.shape[0]\n",
    "t = label_encoder.transform(titanic_X[:, 0]).reshape(num_of_rows, 1)\n",
    "# 다음, 3개 열인 희소 매트릭스를 생성한다 \n",
    "new_features = one_hot_encoder.transform(t)\n",
    "# titanix_X에 새로운 속성을 추가한다\n",
    "titanic_X = np.concatenate([titanic_X, new_features.toarray()], axis = 1)\n",
    "# 변환된 열을 제거한다\n",
    "titanic_X = np.delete(titanic_X, [0], 1)\n",
    "# 속성 이름을 갱신한다\n",
    "feature_names = ['age', 'sex', 'first_class', 'second_class', 'third_class']\n",
    "# 수치 값으로 변환한다\n",
    "titanic_X = titanic_X.astype(float)\n",
    "titanic_y = titanic_y.astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'sex', 'first_class', 'second_class', 'third_class']\n",
      "[ 29.   0.   1.   0.   0.] 1.0\n"
     ]
    }
   ],
   "source": [
    "print feature_names\n",
    "print titanic_X[0], titanic_y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 데이터와 테스테 데이터를 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(titanic_X, titanic_y, test_size=0.25, random_state=33)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결정 트리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터로 결정 트리를 적합화한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier(criterion='entropy', max_depth=3,min_samples_leaf=5)\n",
    "clf = clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pydot를 사용하여 결정 트리를 츨력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named pydot",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-2eb573363201>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mStringIO\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdot_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStringIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport_graphviz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'age'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'sex'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'1st_class'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'2nd_class'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'3rd_class'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_from_dot_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_png\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'titanic.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named pydot"
     ]
    }
   ],
   "source": [
    "import pydot,StringIO\n",
    "dot_data = StringIO.StringIO() \n",
    "tree.export_graphviz(clf, out_file=dot_data, feature_names=['age','sex','1st_class','2nd_class','3rd_class']) \n",
    "graph = pydot.graph_from_dot_data(dot_data.getvalue()) \n",
    "graph.write_png('titanic.png') \n",
    "from IPython.core.display import Image \n",
    "Image(filename='titanic.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 데이터의 정확도(accuracy), 정밀도(precision), 재현율(recall), f1을 측정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.838 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "def measure_performance(X,y,clf, show_accuracy=True, show_classification_report=True, show_confusion_matrix=True):\n",
    "    y_pred=clf.predict(X)   \n",
    "    if show_accuracy:\n",
    "        print \"Accuracy:{0:.3f}\".format(metrics.accuracy_score(y,y_pred)),\"\\n\"\n",
    "\n",
    "    if show_classification_report:\n",
    "        print \"Classification report\"\n",
    "        print metrics.classification_report(y,y_pred),\"\\n\"\n",
    "        \n",
    "    if show_confusion_matrix:\n",
    "        print \"Confusion matrix\"\n",
    "        print metrics.confusion_matrix(y,y_pred),\"\\n\"\n",
    "        \n",
    "measure_performance(X_train,y_train,clf, show_classification_report=False, show_confusion_matrix=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "변화량을 줄이고 좀 더 나은 성능을 얻기 위해, 단일 잔류(leave-one-out) 교차 검증을 실행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score, LeaveOneOut\n",
    "from scipy.stats import sem\n",
    "\n",
    "def loo_cv(X_train,y_train,clf):\n",
    "    # 단일 잔류(Leave-One-Out) 교차 검증 실행한다\n",
    "    loo = LeaveOneOut(X_train[:].shape[0])\n",
    "    scores=np.zeros(X_train[:].shape[0])\n",
    "    for train_index,test_index in loo:\n",
    "        X_train_cv, X_test_cv= X_train[train_index], X_train[test_index]\n",
    "        y_train_cv, y_test_cv= y_train[train_index], y_train[test_index]\n",
    "        clf = clf.fit(X_train_cv,y_train_cv)\n",
    "        y_pred=clf.predict(X_test_cv)\n",
    "        scores[test_index]=metrics.accuracy_score(y_test_cv.astype(int), y_pred.astype(int))\n",
    "    print (\"Mean score: {0:.3f} (+/-{1:.3f})\").format(np.mean(scores), sem(scores))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score: 0.837 (+/-0.012)\n"
     ]
    }
   ],
   "source": [
    "loo_cv(X_train, y_train,clf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "랜덤 포레스트(Random Forests)을 사용하여 성능을 향상한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score: 0.817 (+/-0.012)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=10,random_state=33)\n",
    "clf = clf.fit(X_train,y_train)\n",
    "loo_cv(X_train,y_train,clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "미래 데이터에 대한 성능을 평가하기 위해, 훈련 데이터와 테스트 데이터로 평가한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.793 \n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.77      0.96      0.85       202\n",
      "        1.0       0.88      0.54      0.67       127\n",
      "\n",
      "avg / total       0.81      0.79      0.78       329\n",
      "\n",
      "\n",
      "Confusion matrix\n",
      "[[193   9]\n",
      " [ 59  68]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_dt=tree.DecisionTreeClassifier(criterion='entropy', max_depth=3,min_samples_leaf=5)\n",
    "clf_dt.fit(X_train,y_train)\n",
    "measure_performance(X_test,y_test,clf_dt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
